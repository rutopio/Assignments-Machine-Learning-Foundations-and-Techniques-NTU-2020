{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- R09946006 | HO Ching-Ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4435,)\n",
      "(4435,)\n"
     ]
    }
   ],
   "source": [
    "from svm import *\n",
    "from svmutil import *\n",
    "import numpy as np\n",
    "\n",
    "y_train, x_train = svm_read_problem(\"satimage.scale\")\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "y_test, x_test = svm_read_problem(\"satimage.scale.t\")\n",
    "print(np.shape(y_test))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 15\n",
    "\n",
    "Consider the linear soft-margin SVM. That is, either solve the primal formulation of soft-margin SVM with the given $\\textbf{x}_n$, or take the linear kernel $K(\\textbf{x}_n, \\textbf{x}_m) = \\textbf{x}^T_n \\textbf{x}_m$ in the dual formulation. With $C = 10$, and the binary classification problem of “3” versus “not 3, which of the following numbers is closest to kwk after solving the linear soft-margin SVM? Choose the closest answer; provide your command/code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.459972213043049\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def prob15(x_train, y_train, maxele):\n",
    "    target = 3\n",
    "    y_train_binary = [1 if i==target else 0 for i in y_train] \n",
    "    prob_15  = svm_problem(y_train_binary, x_train)\n",
    "    param_15 = svm_parameter('-t 0 -c 10') # linear (-t 0), cost=10\n",
    "    model_15 = svm_train(prob_15, param_15) \n",
    "    sv_val = list()\n",
    "    for i in range(len(model_15.get_SV())):\n",
    "        if (len(model_15.get_SV()[i].keys())) == maxele:\n",
    "            sv_val.append(list(model_15.get_SV()[i].values()))\n",
    "        else:\n",
    "            tar = model_15.get_SV()[i]\n",
    "            for num in range(1, maxele + 1):\n",
    "                if num not in tar.keys():\n",
    "                    tar[num] = 0\n",
    "            tar = collections.OrderedDict(sorted(tar.items()))\n",
    "            sv_val.append(list(tar.values()))\n",
    "#     w_norm = sv_coef * svs\n",
    "    w_norm = np.linalg.norm(np.dot((np.array(model_15.get_sv_coef())).T, sv_val))\n",
    "    return w_norm\n",
    "            \n",
    "w_norm = prob15(x_train, y_train, 36)\n",
    "print(w_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 16\n",
    "\n",
    "Consider the polynomial kernel $K(\\textbf{x}_n, \\textbf{x}m) = (1 + \\textbf{x}^T_n\\textbf{x}_m)^Q$, where $Q$ is the degree of the  polynomial. With $C = 10$, $Q = 2$, which of the following soft-margin SVM classifiers reaches the lowest $E_{in}$? Choose the correct answer; provide your command/code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 16\n",
      "1 versus not 1\n",
      "0/1 Error = 0.000676\n",
      "--------------------------------------------\n",
      "2 versus not 2\n",
      "0/1 Error = 0.0\n",
      "--------------------------------------------\n",
      "3 versus not 3\n",
      "0/1 Error = 0.022322\n",
      "--------------------------------------------\n",
      "4 versus not 4\n",
      "0/1 Error = 0.040135\n",
      "--------------------------------------------\n",
      "5 versus not 5\n",
      "0/1 Error = 0.006764\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def prob16(ls, x_train, y_train):\n",
    "    print(\"Problem 16\")    \n",
    "    for i in range(len(ls)):\n",
    "        target = ls[i]\n",
    "        print(target, \"versus not\", target)                    \n",
    "        y_train_binary = [1 if i==target else 0 for i in y_train]\n",
    "        prob_16  = svm_problem(y_train_binary, x_train)\n",
    "        param_16 = svm_parameter(\"-t 1 -c 10 -d 2 -g 1 -r 1\") \n",
    "        model_16 = svm_train(prob_16, param_16) \n",
    "        p_label, p_acc, p_val = svm_predict(y_train_binary, x_train, model_16)\n",
    "        err = (1-p_acc[0]/100)\n",
    "        print(\"0/1 Error =\", str(round(err,6)))\n",
    "        print(\"--------------------------------------------\")\n",
    "            \n",
    "ls = [1, 2, 3, 4, 5]\n",
    "prob16(ls, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 17\n",
    "\n",
    "Following Problem 16, which of the following numbers is closest to the maximum number of support vectors within those five soft-margin SVM classifiers? Choose the closest answer; provide your command/code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 17\n",
      "1 versus not 1\n",
      "number of support vectors: 145\n",
      "--------------------------------------------\n",
      "2 versus not 2\n",
      "number of support vectors: 87\n",
      "--------------------------------------------\n",
      "3 versus not 3\n",
      "number of support vectors: 433\n",
      "--------------------------------------------\n",
      "4 versus not 4\n",
      "number of support vectors: 711\n",
      "--------------------------------------------\n",
      "5 versus not 5\n",
      "number of support vectors: 258\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def prob17(ls, x_train, y_train):\n",
    "    print(\"Problem 17\")    \n",
    "    for i in range(len(ls)):\n",
    "        target = ls[i]\n",
    "        print(target, \"versus not\", target)                    \n",
    "        y_train_binary = [1 if i==target else 0 for i in y_train]\n",
    "        prob_17  = svm_problem(y_train_binary, x_train)\n",
    "        param_17 = svm_parameter(\"-t 1 -c 10 -d 2 -g 1 -r 1\") \n",
    "        model_17 = svm_train(prob_17, param_17) \n",
    "        print(\"number of support vectors:\", len(model_17.get_SV()))\n",
    "        print(\"--------------------------------------------\")        \n",
    "            \n",
    "ls = [1, 2, 3, 4, 5]\n",
    "prob17(ls, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 18\n",
    "\n",
    "Consider the Gaussian kernel $K(\\textbf{x}_n, \\textbf{x}_m) = \\exp(-\\gamma||\\textbf{x}_n - \\textbf{x}_m||^2)$. For the binary classification problem of “6” versus “not 6”, when fixing $\\gamma = 10$, which of the following values of $C$ results in the lowest $E_{out}$? Choose the correct answer; provide your command/code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 18\n",
      "6 versus not 6\n",
      "--------------------------------------------\n",
      "C = 0.01\n",
      "0/1 Error = 0.235\n",
      "--------------------------------------------\n",
      "C = 0.1\n",
      "0/1 Error = 0.1635\n",
      "--------------------------------------------\n",
      "C = 1\n",
      "0/1 Error = 0.1065\n",
      "--------------------------------------------\n",
      "C = 10\n",
      "0/1 Error = 0.097\n",
      "--------------------------------------------\n",
      "C = 100\n",
      "0/1 Error = 0.097\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def prob18(target, x_train, y_train, x_test, y_test, c_ls):\n",
    "    print(\"Problem 18\")    \n",
    "    print(target, \"versus not\", target)\n",
    "    print(\"--------------------------------------------\")\n",
    "    y_train_binary = [1 if i==target else 0 for i in y_train]\n",
    "    y_test_binary = [1 if i==target else 0 for i in y_test]\n",
    "    \n",
    "    for i in range(len(c_ls)):\n",
    "        print(\"C =\", c_ls[i])\n",
    "        prob_18  = svm_problem(y_train_binary, x_train)\n",
    "        parastr = \"-t 2 -g 10 -c \"+str(c_ls[i])\n",
    "#         print(parastr)\n",
    "        param_18 = svm_parameter(parastr) \n",
    "        model_18 = svm_train(prob_18, param_18) \n",
    "        p_label, p_acc, p_val = svm_predict(y_test_binary, x_test, model_18)\n",
    "        err = (1-p_acc[0]/100)\n",
    "        print(\"0/1 Error =\", str(round(err,6)))\n",
    "        print(\"--------------------------------------------\")\n",
    "            \n",
    "target = 6\n",
    "c_ls = [0.01, 0.1, 1, 10, 100]\n",
    "prob18(target, x_train, y_train, x_test, y_test, c_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 19\n",
    "\n",
    "Following Problem 18, when fixing $C = 0.1$, which of the following values of $\\gamma$ results in the lowest $E_{out}$? Choose the correct answer; provide your command/code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 19\n",
      "6  versus not 6\n",
      "--------------------------------------------\n",
      "gamma = 0.1\n",
      "0/1 Error = 0.0985\n",
      "--------------------------------------------\n",
      "gamma = 1\n",
      "0/1 Error = 0.07\n",
      "--------------------------------------------\n",
      "gamma = 10\n",
      "0/1 Error = 0.1635\n",
      "--------------------------------------------\n",
      "gamma = 100\n",
      "0/1 Error = 0.235\n",
      "--------------------------------------------\n",
      "gamma = 1000\n",
      "0/1 Error = 0.235\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def prob19(target, x_train, y_train, x_test, y_test, gamma_ls):\n",
    "    print(\"Problem 19\")\n",
    "    print(target, \" versus not\", target)\n",
    "    y_train_binary = [1 if i==target else 0 for i in y_train]\n",
    "    y_test_binary = [1 if i==target else 0 for i in y_test]     \n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    for i in range(len(gamma_ls)):\n",
    "        print(\"gamma =\", gamma_ls[i])\n",
    "        prob_19  = svm_problem(y_train_binary, x_train)\n",
    "        parastr = \"-t 2 -c 0.1 -g \"+str(gamma_ls[i])\n",
    "#         print(parastr)\n",
    "        param_19 = svm_parameter(parastr) \n",
    "        model_19 = svm_train(prob_19, param_19) \n",
    "        p_label, p_acc, p_val = svm_predict(y_test_binary, x_test, model_19)\n",
    "        err = (1-p_acc[0]/100)\n",
    "        print(\"0/1 Error =\", str(round(err,6)))\n",
    "        print(\"--------------------------------------------\")\n",
    "            \n",
    "target = 6\n",
    "gamma_ls = [0.1, 1, 10, 100, 1000]\n",
    "prob19(target, x_train, y_train, x_test, y_test, gamma_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 20\n",
    "\n",
    "Following Problem 18 and consider a validation procedure that randomly samples 200 examples from the training set for validation and leaves the other examples for training $g^{-}_{svm}$. Fix $C = 0.1$ and use the validation procedure to choose the best $\\gamma$ among ${0.1, 1, 10, 100, 1000}$ according to $E_{val}$. If there is a tie of $E_{val}$, choose the smallest $\\gamma$. Repeat the procedure 1000 times.\n",
    "Which of the following values of $\\gamma$ is selected the most number of times? Choose the correct answer; provide your command/code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  versus not 6\n",
      "--------------------------------------------\n",
      "times 0\n",
      "--------------------------------------------\n",
      "times 5\n",
      "--------------------------------------------\n",
      "times 10\n",
      "--------------------------------------------\n",
      "times 15\n",
      "--------------------------------------------\n",
      "times 20\n",
      "--------------------------------------------\n",
      "times 25\n",
      "--------------------------------------------\n",
      "times 30\n",
      "--------------------------------------------\n",
      "times 35\n",
      "--------------------------------------------\n",
      "times 40\n",
      "--------------------------------------------\n",
      "times 45\n",
      "--------------------------------------------\n",
      "times 50\n",
      "--------------------------------------------\n",
      "times 55\n",
      "--------------------------------------------\n",
      "times 60\n",
      "--------------------------------------------\n",
      "times 65\n",
      "--------------------------------------------\n",
      "times 70\n",
      "--------------------------------------------\n",
      "times 75\n",
      "--------------------------------------------\n",
      "times 80\n",
      "--------------------------------------------\n",
      "times 85\n",
      "--------------------------------------------\n",
      "times 90\n",
      "--------------------------------------------\n",
      "times 95\n",
      "--------------------------------------------\n",
      "times 100\n",
      "--------------------------------------------\n",
      "times 105\n",
      "--------------------------------------------\n",
      "times 110\n",
      "--------------------------------------------\n",
      "times 115\n",
      "--------------------------------------------\n",
      "times 120\n",
      "--------------------------------------------\n",
      "times 125\n",
      "--------------------------------------------\n",
      "times 130\n",
      "--------------------------------------------\n",
      "times 135\n",
      "--------------------------------------------\n",
      "times 140\n",
      "--------------------------------------------\n",
      "times 145\n",
      "--------------------------------------------\n",
      "times 150\n",
      "--------------------------------------------\n",
      "times 155\n",
      "--------------------------------------------\n",
      "times 160\n",
      "--------------------------------------------\n",
      "times 165\n",
      "--------------------------------------------\n",
      "times 170\n",
      "--------------------------------------------\n",
      "times 175\n",
      "--------------------------------------------\n",
      "times 180\n",
      "--------------------------------------------\n",
      "times 185\n",
      "--------------------------------------------\n",
      "times 190\n",
      "--------------------------------------------\n",
      "times 195\n",
      "--------------------------------------------\n",
      "times 200\n",
      "--------------------------------------------\n",
      "times 205\n",
      "--------------------------------------------\n",
      "times 210\n",
      "--------------------------------------------\n",
      "times 215\n",
      "--------------------------------------------\n",
      "times 220\n",
      "--------------------------------------------\n",
      "times 225\n",
      "--------------------------------------------\n",
      "times 230\n",
      "--------------------------------------------\n",
      "times 235\n",
      "--------------------------------------------\n",
      "times 240\n",
      "--------------------------------------------\n",
      "times 245\n",
      "--------------------------------------------\n",
      "times 250\n",
      "--------------------------------------------\n",
      "times 255\n",
      "--------------------------------------------\n",
      "times 260\n",
      "--------------------------------------------\n",
      "times 265\n",
      "--------------------------------------------\n",
      "times 270\n",
      "--------------------------------------------\n",
      "times 275\n",
      "--------------------------------------------\n",
      "times 280\n",
      "--------------------------------------------\n",
      "times 285\n",
      "--------------------------------------------\n",
      "times 290\n",
      "--------------------------------------------\n",
      "times 295\n",
      "--------------------------------------------\n",
      "times 300\n",
      "--------------------------------------------\n",
      "times 305\n",
      "--------------------------------------------\n",
      "times 310\n",
      "--------------------------------------------\n",
      "times 315\n",
      "--------------------------------------------\n",
      "times 320\n",
      "--------------------------------------------\n",
      "times 325\n",
      "--------------------------------------------\n",
      "times 330\n",
      "--------------------------------------------\n",
      "times 335\n",
      "--------------------------------------------\n",
      "times 340\n",
      "--------------------------------------------\n",
      "times 345\n",
      "--------------------------------------------\n",
      "times 350\n",
      "--------------------------------------------\n",
      "times 355\n",
      "--------------------------------------------\n",
      "times 360\n",
      "--------------------------------------------\n",
      "times 365\n",
      "--------------------------------------------\n",
      "times 370\n",
      "--------------------------------------------\n",
      "times 375\n",
      "--------------------------------------------\n",
      "times 380\n",
      "--------------------------------------------\n",
      "times 385\n",
      "--------------------------------------------\n",
      "times 390\n",
      "--------------------------------------------\n",
      "times 395\n",
      "--------------------------------------------\n",
      "times 400\n",
      "--------------------------------------------\n",
      "times 405\n",
      "--------------------------------------------\n",
      "times 410\n",
      "--------------------------------------------\n",
      "times 415\n",
      "--------------------------------------------\n",
      "times 420\n",
      "--------------------------------------------\n",
      "times 425\n",
      "--------------------------------------------\n",
      "times 430\n",
      "--------------------------------------------\n",
      "times 435\n",
      "--------------------------------------------\n",
      "times 440\n",
      "--------------------------------------------\n",
      "times 445\n",
      "--------------------------------------------\n",
      "times 450\n",
      "--------------------------------------------\n",
      "times 455\n",
      "--------------------------------------------\n",
      "times 460\n",
      "--------------------------------------------\n",
      "times 465\n",
      "--------------------------------------------\n",
      "times 470\n",
      "--------------------------------------------\n",
      "times 475\n",
      "--------------------------------------------\n",
      "times 480\n",
      "--------------------------------------------\n",
      "times 485\n",
      "--------------------------------------------\n",
      "times 490\n",
      "--------------------------------------------\n",
      "times 495\n",
      "--------------------------------------------\n",
      "times 500\n",
      "--------------------------------------------\n",
      "times 505\n",
      "--------------------------------------------\n",
      "times 510\n",
      "--------------------------------------------\n",
      "times 515\n",
      "--------------------------------------------\n",
      "times 520\n",
      "--------------------------------------------\n",
      "times 525\n",
      "--------------------------------------------\n",
      "times 530\n",
      "--------------------------------------------\n",
      "times 535\n",
      "--------------------------------------------\n",
      "times 540\n",
      "--------------------------------------------\n",
      "times 545\n",
      "--------------------------------------------\n",
      "times 550\n",
      "--------------------------------------------\n",
      "times 555\n",
      "--------------------------------------------\n",
      "times 560\n",
      "--------------------------------------------\n",
      "times 565\n",
      "--------------------------------------------\n",
      "times 570\n",
      "--------------------------------------------\n",
      "times 575\n",
      "--------------------------------------------\n",
      "times 580\n",
      "--------------------------------------------\n",
      "times 585\n",
      "--------------------------------------------\n",
      "times 590\n",
      "--------------------------------------------\n",
      "times 595\n",
      "--------------------------------------------\n",
      "times 600\n",
      "--------------------------------------------\n",
      "times 605\n",
      "--------------------------------------------\n",
      "times 610\n",
      "--------------------------------------------\n",
      "times 615\n",
      "--------------------------------------------\n",
      "times 620\n",
      "--------------------------------------------\n",
      "times 625\n",
      "--------------------------------------------\n",
      "times 630\n",
      "--------------------------------------------\n",
      "times 635\n",
      "--------------------------------------------\n",
      "times 640\n",
      "--------------------------------------------\n",
      "times 645\n",
      "--------------------------------------------\n",
      "times 650\n",
      "--------------------------------------------\n",
      "times 655\n",
      "--------------------------------------------\n",
      "times 660\n",
      "--------------------------------------------\n",
      "times 665\n",
      "--------------------------------------------\n",
      "times 670\n",
      "--------------------------------------------\n",
      "times 675\n",
      "--------------------------------------------\n",
      "times 680\n",
      "--------------------------------------------\n",
      "times 685\n",
      "--------------------------------------------\n",
      "times 690\n",
      "--------------------------------------------\n",
      "times 695\n",
      "--------------------------------------------\n",
      "times 700\n",
      "--------------------------------------------\n",
      "times 705\n",
      "--------------------------------------------\n",
      "times 710\n",
      "--------------------------------------------\n",
      "times 715\n",
      "--------------------------------------------\n",
      "times 720\n",
      "--------------------------------------------\n",
      "times 725\n",
      "--------------------------------------------\n",
      "times 730\n",
      "--------------------------------------------\n",
      "times 735\n",
      "--------------------------------------------\n",
      "times 740\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times 745\n",
      "--------------------------------------------\n",
      "times 750\n",
      "--------------------------------------------\n",
      "times 755\n",
      "--------------------------------------------\n",
      "times 760\n",
      "--------------------------------------------\n",
      "times 765\n",
      "--------------------------------------------\n",
      "times 770\n",
      "--------------------------------------------\n",
      "times 775\n",
      "--------------------------------------------\n",
      "times 780\n",
      "--------------------------------------------\n",
      "times 785\n",
      "--------------------------------------------\n",
      "times 790\n",
      "--------------------------------------------\n",
      "times 795\n",
      "--------------------------------------------\n",
      "times 800\n",
      "--------------------------------------------\n",
      "times 805\n",
      "--------------------------------------------\n",
      "times 810\n",
      "--------------------------------------------\n",
      "times 815\n",
      "--------------------------------------------\n",
      "times 820\n",
      "--------------------------------------------\n",
      "times 825\n",
      "--------------------------------------------\n",
      "times 830\n",
      "--------------------------------------------\n",
      "times 835\n",
      "--------------------------------------------\n",
      "times 840\n",
      "--------------------------------------------\n",
      "times 845\n",
      "--------------------------------------------\n",
      "times 850\n",
      "--------------------------------------------\n",
      "times 855\n",
      "--------------------------------------------\n",
      "times 860\n",
      "--------------------------------------------\n",
      "times 865\n",
      "--------------------------------------------\n",
      "times 870\n",
      "--------------------------------------------\n",
      "times 875\n",
      "--------------------------------------------\n",
      "times 880\n",
      "--------------------------------------------\n",
      "times 885\n",
      "--------------------------------------------\n",
      "times 890\n",
      "--------------------------------------------\n",
      "times 895\n",
      "--------------------------------------------\n",
      "times 900\n",
      "--------------------------------------------\n",
      "times 905\n",
      "--------------------------------------------\n",
      "times 910\n",
      "--------------------------------------------\n",
      "times 915\n",
      "--------------------------------------------\n",
      "times 920\n",
      "--------------------------------------------\n",
      "times 925\n",
      "--------------------------------------------\n",
      "times 930\n",
      "--------------------------------------------\n",
      "times 935\n",
      "--------------------------------------------\n",
      "times 940\n",
      "--------------------------------------------\n",
      "times 945\n",
      "--------------------------------------------\n",
      "times 950\n",
      "--------------------------------------------\n",
      "times 955\n",
      "--------------------------------------------\n",
      "times 960\n",
      "--------------------------------------------\n",
      "times 965\n",
      "--------------------------------------------\n",
      "times 970\n",
      "--------------------------------------------\n",
      "times 975\n",
      "--------------------------------------------\n",
      "times 980\n",
      "--------------------------------------------\n",
      "times 985\n",
      "--------------------------------------------\n",
      "times 990\n",
      "--------------------------------------------\n",
      "times 995\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "def prob20(target, x_train, y_train, gamma_ls, size_validation, times):\n",
    "    print(target, \" versus not\", target)\n",
    "    y_train_binary = [1 if i==target else 0 for i in y_train]        \n",
    "    print(\"--------------------------------------------\")\n",
    "    pos = list()\n",
    "    random.seed(5566)        \n",
    "    for j in range(times):\n",
    "        if (j%5==0):\n",
    "            print(\"times\", j)\n",
    "            print(\"--------------------------------------------\")            \n",
    "        rd_ls = random.sample(range(len(x_train)), 200)\n",
    "        x_validation_ = list()\n",
    "        y_validation_ = list()\n",
    "        x_train_ = list()\n",
    "        y_train_ = list()\n",
    "        # sample validation set\n",
    "        for i in range(len(x_train)):\n",
    "            if i in rd_ls:\n",
    "                x_validation_.append(x_train[i])\n",
    "                y_validation_.append(y_train[i])\n",
    "\n",
    "            else:\n",
    "                x_train_.append(x_train[i])\n",
    "                y_train_.append(y_train[i])\n",
    "        gamma_err_ls = []\n",
    "        for i in range(len(gamma_ls)):                \n",
    "#             print(\"gamma =\", gamma_ls[i])                     \n",
    "            prob_20  = svm_problem(y_train_, x_train_)\n",
    "            parastr = str(\"-t 2 -c 0.1 -g \"+str(gamma_ls[i]))\n",
    "#             print(parastr)\n",
    "            param_20 = svm_parameter(parastr) \n",
    "            model_20 = svm_train(prob_20, param_20) \n",
    "\n",
    "            p_label, p_acc, p_val = svm_predict(y_validation_, x_validation_, model_20)\n",
    "            err = (1-p_acc[0]/100)\n",
    "#             print(err)\n",
    "            gamma_err_ls.append(err)\n",
    "#         print(gamma_err_ls)\n",
    "        smallest_pos = gamma_err_ls.index(min(gamma_err_ls)) \n",
    "        pos.append(smallest_pos)\n",
    "        \n",
    "    return pos\n",
    "#             print(\"0/1 Error =\", str(round(err,6)))\n",
    "#     err_sum_ls.append(err_sum)\n",
    "#     return err_sum_ls\n",
    "            \n",
    "target = 6\n",
    "size_validation = 200\n",
    "gamma_ls = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "prob20_err_pos_ls = prob20(target, x_train, y_train, gamma_ls, size_validation, 1000)\n",
    "prob20_err_pos_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem 20\n",
      "number of different gamma selected in 1000 iterations\n",
      "--------------------------------------------\n",
      "gmma=0.1: 124\n",
      "gmma=1: 876\n",
      "gmma=10: 0\n",
      "gmma=100: 0\n",
      "gmma=1000: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Problem 20\")\n",
    "print(\"number of different gamma selected in 1000 iterations\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"gmma=0.1:\", prob20_err_pos_ls.count(0))\n",
    "print(\"gmma=1:\", prob20_err_pos_ls.count(1))\n",
    "print(\"gmma=10:\", prob20_err_pos_ls.count(2))\n",
    "print(\"gmma=100:\", prob20_err_pos_ls.count(3))\n",
    "print(\"gmma=1000:\", prob20_err_pos_ls.count(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
